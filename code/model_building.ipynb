{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing preprocessed data sets\n",
    "train = pd.read_csv('../preprocess_data/train.csv')\n",
    "test = pd.read_csv('../preprocess_data/test.csv')\n",
    "\n",
    "# Dropping the index column\n",
    "train = train.drop(columns = 'Unnamed: 0')\n",
    "test = test.drop(columns = 'Unnamed: 0')\n",
    "\n",
    "# Splitting in X and y \n",
    "X_train = train.iloc[:, :-1]\n",
    "y_train = train.iloc[:, -1]\n",
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test.iloc[:, -1]\n",
    "\n",
    "# Replacing inf values with the maximum float number\n",
    "X_train.replace([np.inf, -np.inf], np.finfo(np.float32).max, inplace = True)\n",
    "X_train.fillna(X_train.mean(), inplace = True)\n",
    "X_test.replace([np.inf, -np.inf], np.finfo(np.float32).max, inplace = True)\n",
    "X_test.fillna(X_train.mean(), inplace = True) # using the mean of the training data to prevent data leakage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Using Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions to calculate information gain\n",
    "def entropy(labels):\n",
    "    \"\"\"Compute the entropy of a list of labels.\"\"\"\n",
    "    n_labels = len(labels)\n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "    value_counts = labels.value_counts() / n_labels\n",
    "    entropy = -np.sum(value_counts * np.log2(value_counts))\n",
    "    return entropy\n",
    "\n",
    "def information_gain(data, labels, attribute):\n",
    "    \"\"\"Compute the information gain for a given attribute.\"\"\"\n",
    "    # Calculate total entropy before splitting\n",
    "    total_entropy = entropy(labels)\n",
    "    \n",
    "    # Calculate the weighted entropy after splitting by the given attribute\n",
    "    weighted_entropy = 0\n",
    "    for value in attribute.unique():\n",
    "        subset_labels = labels[attribute == value]\n",
    "        weighted_entropy += (len(subset_labels) / len(labels)) * entropy(subset_labels)\n",
    "    \n",
    "    # Information gain is the difference between total entropy and weighted entropy\n",
    "    info_gain = total_entropy - weighted_entropy\n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing information gain for each attribute\n",
    "info_gain_dict = {}\n",
    "for column in X_train:\n",
    "    info_gain_dict[column] = information_gain(X_train, y_train, X_train[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Flow Bytes/s', 0.7498814412155748),\n",
       " (' Average Packet Size', 0.7213538835256111),\n",
       " (' Packet Length Std', 0.7116909331054498),\n",
       " (' Flow Packets/s', 0.7094301317451537),\n",
       " (' Packet Length Variance', 0.7089655874631503),\n",
       " ('Fwd Packets/s', 0.7081283054392367),\n",
       " (' Packet Length Mean', 0.6816263462323534),\n",
       " (' Flow Duration', 0.6802507170926715),\n",
       " (' Flow IAT Mean', 0.67627780578498),\n",
       " (' Bwd Packets/s', 0.6518162523049276),\n",
       " (' Flow IAT Max', 0.632708755195615),\n",
       " (' Destination Port', 0.6264352915685752),\n",
       " (' Total Length of Bwd Packets', 0.6130724669754792),\n",
       " (' Subflow Bwd Bytes', 0.6130724669754792),\n",
       " (' Bwd Packet Length Mean', 0.5991204518025013),\n",
       " (' Avg Bwd Segment Size', 0.5991204518025013),\n",
       " ('Bwd Packet Length Max', 0.5592241210723775),\n",
       " ('Total Length of Fwd Packets', 0.5588915667948694),\n",
       " (' Subflow Fwd Bytes', 0.5588915667948694),\n",
       " (' Fwd IAT Mean', 0.5585074120901432),\n",
       " (' Init_Win_bytes_backward', 0.5547067518899622),\n",
       " (' Fwd IAT Max', 0.5457801816700032),\n",
       " ('Init_Win_bytes_forward', 0.5424621076278054),\n",
       " (' Flow IAT Std', 0.5334432962170053),\n",
       " ('Fwd IAT Total', 0.5282263226470578),\n",
       " (' Max Packet Length', 0.5130003747125209),\n",
       " (' Fwd Packet Length Max', 0.49856719332268734),\n",
       " (' Fwd Packet Length Mean', 0.4615588692504838),\n",
       " (' Avg Fwd Segment Size', 0.4615588692504838),\n",
       " (' Bwd Header Length', 0.4472679868844703),\n",
       " (' Fwd IAT Std', 0.44051554552687583),\n",
       " (' Bwd IAT Mean', 0.4388403680619971),\n",
       " (' Fwd Header Length', 0.43345272702725524),\n",
       " (' Bwd IAT Max', 0.4297016210255047),\n",
       " ('Bwd IAT Total', 0.4172609034112005),\n",
       " (' Fwd Packet Length Std', 0.3839763466866458),\n",
       " (' Bwd Packet Length Std', 0.3637832849199817),\n",
       " (' Bwd IAT Std', 0.357054444309022),\n",
       " (' Total Backward Packets', 0.35355337756581073),\n",
       " (' Subflow Bwd Packets', 0.35355337756581073),\n",
       " (' Bwd Packet Length Min', 0.3245852285503762),\n",
       " (' Total Fwd Packets', 0.2913663403061315),\n",
       " ('Subflow Fwd Packets', 0.2913663403061315),\n",
       " ('Active Mean', 0.25625995971073756),\n",
       " (' Active Max', 0.2559921935946685),\n",
       " (' Active Min', 0.2519529849421256),\n",
       " (' Fwd IAT Min', 0.2486004244312403),\n",
       " (' Idle Min', 0.23969212935787587),\n",
       " (' Bwd IAT Min', 0.23647572764409486),\n",
       " (' Fwd Packet Length Min', 0.2335853350692929),\n",
       " (' Idle Max', 0.2332045908953181),\n",
       " (' Min Packet Length', 0.23128949244558894),\n",
       " ('Idle Mean', 0.22871155168650936),\n",
       " (' min_seg_size_forward', 0.2262478481808099),\n",
       " (' Flow IAT Min', 0.22408482012068198),\n",
       " (' act_data_pkt_fwd', 0.18581144875760192),\n",
       " (' PSH Flag Count', 0.10628392890505567),\n",
       " (' Down/Up Ratio', 0.08794460441618568),\n",
       " (' ACK Flag Count', 0.06961595607973603),\n",
       " (' Idle Std', 0.03873338447093888),\n",
       " ('FIN Flag Count', 0.03269904511007948),\n",
       " (' URG Flag Count', 0.028009975167097134),\n",
       " (' Active Std', 0.02602584591302548),\n",
       " ('Fwd PSH Flags', 0.012359266043303285),\n",
       " (' SYN Flag Count', 0.012359266043303285),\n",
       " (' RST Flag Count', 8.46980696402877e-05),\n",
       " (' ECE Flag Count', 8.46980696402877e-05),\n",
       " (' Fwd URG Flags', 3.195855929216673e-05),\n",
       " (' CWE Flag Count', 3.195855929216673e-05),\n",
       " (' Bwd PSH Flags', 0.0),\n",
       " (' Bwd URG Flags', 0.0),\n",
       " ('Fwd Avg Bytes/Bulk', 0.0),\n",
       " (' Fwd Avg Packets/Bulk', 0.0),\n",
       " (' Fwd Avg Bulk Rate', 0.0),\n",
       " (' Bwd Avg Bytes/Bulk', 0.0),\n",
       " (' Bwd Avg Packets/Bulk', 0.0),\n",
       " ('Bwd Avg Bulk Rate', 0.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the information gains in descending order\n",
    "sorted(info_gain_dict.items(), key = operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Feature Groups Based on Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating feature groups using the same thresholds as the research paper\n",
    "# Note: if a feature is greater than 0.6 then it will also be included in the greater 0.5, 0.4, 0.3, 0.2, and 0.1 groups\n",
    "info_gain_gt06 = []\n",
    "info_gain_gt05 = []\n",
    "info_gain_gt04 = []\n",
    "info_gain_gt03 = []\n",
    "info_gain_gt02 = []\n",
    "info_gain_gt01 = []\n",
    "all_features = list(X_train.columns)\n",
    "\n",
    "for key, val in info_gain_dict.items():\n",
    "    if val > 0.6:\n",
    "        info_gain_gt06.append(key)\n",
    "    if val > 0.5: \n",
    "        info_gain_gt05.append(key)\n",
    "    if val > 0.4:\n",
    "        info_gain_gt04.append(key)\n",
    "    if val > 0.3:\n",
    "        info_gain_gt03.append(key)\n",
    "    if val > 0.2:\n",
    "        info_gain_gt02.append(key)\n",
    "    if val > 0.1:\n",
    "        info_gain_gt01.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Groups:\n",
      "Information Gain > 0.6: 14\n",
      "Information Gain > 0.5: 26\n",
      "Information Gain > 0.4: 35\n",
      "Information Gain > 0.3: 41\n",
      "Information Gain > 0.2: 55\n",
      "Information Gain > 0.1: 57\n",
      "All Features: 77\n"
     ]
    }
   ],
   "source": [
    "# Printing the number of features in each Feature Group\n",
    "print('Feature Groups:')\n",
    "print(f'Information Gain > 0.6: {len(info_gain_gt06)}')\n",
    "print(f'Information Gain > 0.5: {len(info_gain_gt05)}')\n",
    "print(f'Information Gain > 0.4: {len(info_gain_gt04)}')\n",
    "print(f'Information Gain > 0.3: {len(info_gain_gt03)}')\n",
    "print(f'Information Gain > 0.2: {len(info_gain_gt02)}')\n",
    "print(f'Information Gain > 0.1: {len(info_gain_gt01)}')\n",
    "print(f'All Features: {len(all_features)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Classification Models for Each Feature Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Group 1: Information Gain > 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "# Data Preprocessing for Random Forest\n",
    "warnings.filterwarnings('ignore')\n",
    "## Converting categorical label column into numeric \n",
    "# Define a mapping dictionary for category to numeric value\n",
    "category_mapping = {'Normal': 0, 'Bot': 1, 'Brute Force': 2, 'DoS/DdoS': 3, 'Infiltration': 4, 'Portscan': 5, 'Web Attack': 6}\n",
    "# Map the categorical values to numeric values using the mapping dictionary\n",
    "y_train_encoded = y_train.map(category_mapping)\n",
    "y_test_encoded = y_test.map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9961553180841355\n"
     ]
    }
   ],
   "source": [
    "## Random Forest classifier\n",
    "rf_model_fg1 = RandomForestClassifier()\n",
    "rf_model_fg1.fit(X_train[info_gain_gt06], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "rf_pred_fg1 = rf_model_fg1.predict(X_test[info_gain_gt06])\n",
    "\n",
    "rf_accuracy_fg1 = accuracy_score(y_test_encoded, rf_pred_fg1)\n",
    "print('Random Forest Accuracy:', rf_accuracy_fg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Accuracy: 0.9948070299390621\n"
     ]
    }
   ],
   "source": [
    "## Random Tree classifier\n",
    "rt_model_fg1 = RandomForestClassifier(n_estimators = 1) # setting n_estimator to 1 is only using a single tree instead of a forest of trees\n",
    "rt_model_fg1.fit(X_train[info_gain_gt06], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "rt_pred_fg1 = rt_model_fg1.predict(X_test[info_gain_gt06])\n",
    "\n",
    "rt_accuracy_fg1 = accuracy_score(y_test_encoded, rt_pred_fg1)\n",
    "print('Random Tree Accuracy:', rt_accuracy_fg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy 0.004604197945185316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Instantiate the Gaussian Naive Bayes classifier\n",
    "nb_model_fg1 = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_model_fg1.fit(X_train[info_gain_gt06], y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_pred_fg1 = nb_model_fg1.predict(X_test[info_gain_gt06])\n",
    "\n",
    "# Evaluate the model\n",
    "nb_accuracy_fg1 = accuracy_score(y_test, nb_pred_fg1)\n",
    "print('Naive Bayes Accuracy', nb_accuracy_fg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Group 2: Information Gain > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9981159292295917\n"
     ]
    }
   ],
   "source": [
    "## Random Forest classifier\n",
    "rf_model_fg2 = RandomForestClassifier()\n",
    "rf_model_fg2.fit(X_train[info_gain_gt05], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "y_pred_fg2 = rf_model_fg2.predict(X_test[info_gain_gt05])\n",
    "\n",
    "accuracy_fg2 = accuracy_score(y_test_encoded, y_pred_fg2)\n",
    "print('Random Forest Accuracy:', accuracy_fg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Accuracy: 0.9967440901998882\n"
     ]
    }
   ],
   "source": [
    "## Random Tree classifier\n",
    "rt_model_fg2 = RandomForestClassifier(n_estimators = 1) # setting n_estimator to 1 is only using a single tree instead of a forest of trees\n",
    "rt_model_fg2.fit(X_train[info_gain_gt05], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "rt_pred_fg2 = rt_model_fg2.predict(X_test[info_gain_gt05])\n",
    "\n",
    "rt_accuracy_fg2 = accuracy_score(y_test_encoded, rt_pred_fg2)\n",
    "print('Random Tree Accuracy:', rt_accuracy_fg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy 0.004604197945185316\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Gaussian Naive Bayes classifier\n",
    "nb_model_fg2 = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_model_fg2.fit(X_train[info_gain_gt05], y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_pred_fg2 = nb_model_fg2.predict(X_test[info_gain_gt05])\n",
    "\n",
    "# Evaluate the model\n",
    "nb_accuracy_fg2 = accuracy_score(y_test, nb_pred_fg2)\n",
    "print('Naive Bayes Accuracy', nb_accuracy_fg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Group 3: Information Gain > 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9982748977008449\n"
     ]
    }
   ],
   "source": [
    "## Random Forest classifier\n",
    "rf_model_fg3 = RandomForestClassifier()\n",
    "rf_model_fg3.fit(X_train[info_gain_gt04], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "y_pred_fg3 = rf_model_fg3.predict(X_test[info_gain_gt04])\n",
    "\n",
    "accuracy_fg3 = accuracy_score(y_test_encoded, y_pred_fg3)\n",
    "print('Random Forest Accuracy:', accuracy_fg3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Accuracy: 0.9970973534693397\n"
     ]
    }
   ],
   "source": [
    "## Random Tree classifier\n",
    "rt_model_fg3 = RandomForestClassifier(n_estimators = 1) # setting n_estimator to 1 is only using a single tree instead of a forest of trees\n",
    "rt_model_fg3.fit(X_train[info_gain_gt04], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "rt_pred_fg3 = rt_model_fg3.predict(X_test[info_gain_gt04])\n",
    "\n",
    "rt_accuracy_fg3 = accuracy_score(y_test_encoded, rt_pred_fg3)\n",
    "print('Random Tree Accuracy:', rt_accuracy_fg3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy 0.004604197945185316\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Gaussian Naive Bayes classifier\n",
    "nb_model_fg3 = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_model_fg3.fit(X_train[info_gain_gt04], y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_pred_fg3 = nb_model_fg3.predict(X_test[info_gain_gt04])\n",
    "\n",
    "# Evaluate the model\n",
    "nb_accuracy_fg3 = accuracy_score(y_test, nb_pred_fg3)\n",
    "print('Naive Bayes Accuracy', nb_accuracy_fg3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Group 4: Information Gain > 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9982513468162147\n"
     ]
    }
   ],
   "source": [
    "## Random Forest classifier\n",
    "rf_model_fg4 = RandomForestClassifier()\n",
    "rf_model_fg4.fit(X_train[info_gain_gt03], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "y_pred_fg4 = rf_model_fg4.predict(X_test[info_gain_gt03])\n",
    "\n",
    "accuracy_fg4 = accuracy_score(y_test_encoded, y_pred_fg4)\n",
    "print('Random Forest Accuracy:', accuracy_fg4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Accuracy: 0.9974447290176337\n"
     ]
    }
   ],
   "source": [
    "## Random Tree classifier\n",
    "rt_model_fg4 = RandomForestClassifier(n_estimators = 1) # setting n_estimator to 1 is only using a single tree instead of a forest of trees\n",
    "rt_model_fg4.fit(X_train[info_gain_gt03], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "rt_pred_fg4 = rt_model_fg4.predict(X_test[info_gain_gt03])\n",
    "\n",
    "rt_accuracy_fg4 = accuracy_score(y_test_encoded, rt_pred_fg4)\n",
    "print('Random Tree Accuracy:', rt_accuracy_fg4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy 0.004604197945185316\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Gaussian Naive Bayes classifier\n",
    "nb_model_fg4 = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_model_fg4.fit(X_train[info_gain_gt03], y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_pred_fg4 = nb_model_fg4.predict(X_test[info_gain_gt03])\n",
    "\n",
    "# Evaluate the model\n",
    "nb_accuracy_fg4 = accuracy_score(y_test, nb_pred_fg4)\n",
    "print('Naive Bayes Accuracy', nb_accuracy_fg4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Group 5: Information Gain > 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9983219994701051\n"
     ]
    }
   ],
   "source": [
    "## Random Forest classifier\n",
    "rf_model_fg5 = RandomForestClassifier()\n",
    "rf_model_fg5.fit(X_train[info_gain_gt02], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "y_pred_fg5 = rf_model_fg5.predict(X_test[info_gain_gt02])\n",
    "\n",
    "accuracy_fg5 = accuracy_score(y_test_encoded, y_pred_fg5)\n",
    "print('Random Forest Accuracy:', accuracy_fg5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Accuracy: 0.9972092201713327\n"
     ]
    }
   ],
   "source": [
    "## Random Tree classifier\n",
    "rt_model_fg5 = RandomForestClassifier(n_estimators = 1) # setting n_estimator to 1 is only using a single tree instead of a forest of trees\n",
    "rt_model_fg5.fit(X_train[info_gain_gt02], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "rt_pred_fg5 = rt_model_fg5.predict(X_test[info_gain_gt02])\n",
    "\n",
    "rt_accuracy_fg5 = accuracy_score(y_test_encoded, rt_pred_fg5)\n",
    "print('Random Tree Accuracy:', rt_accuracy_fg5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy 0.004604197945185316\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Gaussian Naive Bayes classifier\n",
    "nb_model_fg5 = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_model_fg5.fit(X_train[info_gain_gt02], y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_pred_fg5 = nb_model_fg5.predict(X_test[info_gain_gt02])\n",
    "\n",
    "# Evaluate the model\n",
    "nb_accuracy_fg5 = accuracy_score(y_test, nb_pred_fg5)\n",
    "print('Naive Bayes Accuracy', nb_accuracy_fg5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Group 6: Information Gain > 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9983278871912626\n"
     ]
    }
   ],
   "source": [
    "## Random Forest classifier\n",
    "rf_model_fg6 = RandomForestClassifier()\n",
    "rf_model_fg6.fit(X_train[info_gain_gt01], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "y_pred_fg6 = rf_model_fg6.predict(X_test[info_gain_gt01])\n",
    "\n",
    "accuracy_fg6 = accuracy_score(y_test_encoded, y_pred_fg6)\n",
    "print('Random Forest Accuracy:', accuracy_fg6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Accuracy: 0.9968500691807236\n"
     ]
    }
   ],
   "source": [
    "## Random Tree classifier\n",
    "rt_model_fg6 = RandomForestClassifier(n_estimators = 1) # setting n_estimator to 1 is only using a single tree instead of a forest of trees\n",
    "rt_model_fg6.fit(X_train[info_gain_gt01], y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "rt_pred_fg6 = rt_model_fg6.predict(X_test[info_gain_gt01])\n",
    "\n",
    "rt_accuracy_fg6 = accuracy_score(y_test_encoded, rt_pred_fg6)\n",
    "print('Random Tree Accuracy:', rt_accuracy_fg6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy 0.004604197945185316\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Gaussian Naive Bayes classifier\n",
    "nb_model_fg6 = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_model_fg6.fit(X_train[info_gain_gt01], y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_pred_fg6 = nb_model_fg6.predict(X_test[info_gain_gt01])\n",
    "\n",
    "# Evaluate the model\n",
    "nb_accuracy_fg6 = accuracy_score(y_test, nb_pred_fg6)\n",
    "print('Naive Bayes Accuracy', nb_accuracy_fg6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Group 7: All Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy 0.9982866731431599\n"
     ]
    }
   ],
   "source": [
    "## Random Forest classifier\n",
    "rf_model_fg7 = RandomForestClassifier()\n",
    "rf_model_fg7.fit(X_train, y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "y_pred_fg7 = rf_model_fg7.predict(X_test)\n",
    "\n",
    "accuracy_fg7 = accuracy_score(y_test_encoded, y_pred_fg7)\n",
    "print('Random Forest Accuracy', accuracy_fg7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Accuracy: 0.9973681886425859\n"
     ]
    }
   ],
   "source": [
    "## Random Tree classifier\n",
    "rt_model_fg7 = RandomForestClassifier(n_estimators = 1) # setting n_estimator to 1 is only using a single tree instead of a forest of trees\n",
    "rt_model_fg7.fit(X_train, y_train_encoded.values.ravel())\n",
    "\n",
    "# Making predictions\n",
    "rt_pred_fg7 = rt_model_fg7.predict(X_test)\n",
    "\n",
    "rt_accuracy_fg7 = accuracy_score(y_test_encoded, rt_pred_fg7)\n",
    "print('Random Tree Accuracy:', rt_accuracy_fg7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy 0.004604197945185316\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Gaussian Naive Bayes classifier\n",
    "nb_model_fg7 = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_model_fg7.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_pred_fg7 = nb_model_fg7.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "nb_accuracy_fg7 = accuracy_score(y_test, nb_pred_fg7)\n",
    "print('Naive Bayes Accuracy', nb_accuracy_fg7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
